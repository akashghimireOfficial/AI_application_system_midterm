
# AI Application System Midterm Assignment

**Task**
> Revise everything from week 3 to week 7 and create a github repository which consist of similar projects learned during the lab session of the respected weeks.

````
Name: Akash Ghimire
student id: 12194814

````

*Tensorflow 2.0 + has been used as Deep learning Framework for this assignment.*


## Strong points of this Repository

1. Each week lab session have its own corresponding folder.
2. Summary of each lab session has been explained beautifully in the Readme.md file.
3. Each jupyter note book file have detailed explanation of lab session. **Theoretical explanation have been explained in well mannered using markdown language in the jupyter notebook.**
4. **Although every jupyter notebook represents similar concepts from lab session, all codes were coded by myself. **

<br>

## Week 3_and_4
In these weeks we learn most of the theoretical stuffs behind how simple preceptons in deep learning networks works. **We learned about basics component of preceptron i.e.weights and bias. We also learn about ** forward passing, activation function, backward passing, loss , and error functions.** 
<br>
> In the lab section we build simple neural network from the scratch. The code can be found under week 3_and_4 folder. The codes are explained well using jupyter notebook markdown language. 



**The code for this session is under week 3_and_4 folder and can be directed from this link [nn from scratch](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/Week%203_and_4/nn_from_scratch.ipynb).**

  

## Week 5
In this week we learned basic of tensors in tensorflow which including creating tensors and performing different mathematical operation with created tensors. Furthermore, we learned about computational graph and visualizing our task using tensorboard to analyse and visualize our task. 
To make the task simpler i have created separate jupyter notebook for each of these smaller tasks.
<br>
The contents of this weeks were: 
> Clicking on the following lists will directly take you the respected jupyter notebook file.
1. [tf.constant and basic tf.math](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_5/Tensors.ipynb)
2. [Gradient Descent](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_5/Automatic_differentiation.ipynb)
3. [tf.Variables](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_5/variables.ipynb)
4. [Graph Computation](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_5/Graphs_and_functions.ipynb)
5. [tf.Summary(Tensorboard Visualization)](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_5/tf_summary.ipynb)


<br>


## Week 6
In this week we have two lab session. In the *first lab session* we learn to train custom made dataset using tensorflow. The training include implementation of a simple linear regression algorithm.  
In the first lab session of this week we learned the following: 1)  training a simple **Linear Regression** model on custom training datasets and 2) training a model on **MNIST**
<br>
**The code for this session is under week 6 folder and can be directed from given [linear regression](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_6/6_1(regression).ipynb) and [MNIST](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_6/6_1(mnist).ipynb).**

<br>

In the *second lab session*, we learned to denoised the image using Deep learning technique known as ***autoencoder***.
<br>
> **An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning).[1] The encoding is validated and refined by attempting to regenerate the input from the encoding. The autoencoder learns a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore insignificant data (“noise”).**


<br>

## Week 7
In this week we learned about theoretical and coding aspects of Convulutional Neural Network(CNN). During the lab session we used cifar 10 datasets and trained our CNN model on it. To visualise the result we use tensorboard callback.
<br>
>**A convolutional neural network (CNN) is a deep learning network architecture that learns directly from data, eliminating the need for manual feature extraction.CNNs are especially useful for detecting patterns in images in order to recognize objects, faces, and scenes.**

<br>


> The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck). There are 6000 images per class with 5000 training and 1000 testing images per class.

**The code for this session is under week 7 folder and can be directed from given [cifar 10(CNN)](https://github.com/akashghimireOfficial/AI_application_system_midterm/blob/master/week_7/week_7(CNN).ipynb).**


  
